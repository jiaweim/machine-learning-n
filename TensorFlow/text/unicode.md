# Unicode å­—ç¬¦ä¸²

- [Unicode å­—ç¬¦ä¸²](#unicode-å­—ç¬¦ä¸²)
  - [1. ç®€ä»‹](#1-ç®€ä»‹)
  - [2. tf.string æ•°æ®ç±»å‹](#2-tfstring-æ•°æ®ç±»å‹)
  - [3. è¡¨ç¤º Unicode](#3-è¡¨ç¤º-unicode)
    - [3.1 ä¸åŒè¡¨ç¤ºä¹‹é—´çš„è½¬æ¢](#31-ä¸åŒè¡¨ç¤ºä¹‹é—´çš„è½¬æ¢)
    - [3.2 batch ç»´åº¦](#32-batch-ç»´åº¦)
  - [4. Unicode æ“ä½œ](#4-unicode-æ“ä½œ)
    - [4.1 å­—ç¬¦é•¿åº¦](#41-å­—ç¬¦é•¿åº¦)
    - [4.2 å­å­—ç¬¦ä¸²](#42-å­å­—ç¬¦ä¸²)
    - [4.3 æ‹†åˆ† Unicode å­—ç¬¦ä¸²](#43-æ‹†åˆ†-unicode-å­—ç¬¦ä¸²)
    - [4.4 Byte offsets for characters](#44-byte-offsets-for-characters)
  - [5. Unicode scripts](#5-unicode-scripts)
  - [6. ç¤ºä¾‹ï¼šç®€å•åˆ†è¯](#6-ç¤ºä¾‹ç®€å•åˆ†è¯)
  - [7. å‚è€ƒ](#7-å‚è€ƒ)

Last updated: 2022-08-08, 17:00
@author Jiawei Mao
****

## 1. ç®€ä»‹

NLP æ¨¡å‹é€šå¸¸éœ€è¦å¤„ç†ä¸åŒè¯­è¨€çš„ä¸åŒå­—ç¬¦é›†ã€‚Unicode æ˜¯ä¸€ä¸ªæ ‡å‡†ç¼–ç ç³»ç»Ÿï¼ŒåŒ…å«å‡ ä¹æ‰€æœ‰è¯­è¨€çš„å­—ç¬¦ã€‚æ¯ä¸ª Unicode å­—ç¬¦ä½¿ç”¨ `0` åˆ° `0x10FFFF` ä¹‹é—´çš„å”¯ä¸€æ•´æ•°ä»£ç ç‚¹è¿›è¡Œç¼–ç ï¼Œä¸€æ¡ Unicode å­—ç¬¦ä¸²æ˜¯ 0 æˆ–å¤šä¸ª unicode ä»£ç ç‚¹çš„åºåˆ—ã€‚

æœ¬æ•™ç¨‹æ¼”ç¤ºå¦‚ä½•åœ¨ TF ä¸­è¡¨ç¤º Unicode å­—ç¬¦ä¸²ï¼Œå¹¶ä½¿ç”¨ä¸æ ‡å‡†å­—ç¬¦ä¸²æ“ä½œç­‰ä»·çš„ Unicode æ“ä½œè¿›è¡Œå¤„ç†ã€‚åŸºäº script æ£€æµ‹æ‹†åˆ† Unicode å­—ç¬¦ä¸²ä¸º tokensã€‚

```python
import tensorflow as tf
import numpy as np
```

## 2. tf.string æ•°æ®ç±»å‹

å¯ä»¥ä½¿ç”¨åŸºæœ¬çš„ `tf.string` dtype æ„å»º byte å­—ç¬¦ä¸²å¼ é‡ã€‚Unicode å­—ç¬¦ä¸²é»˜è®¤ä½¿ç”¨ [utf-8](https://en.wikipedia.org/wiki/UTF-8) ç¼–ç ã€‚

```python
tf.constant(u"Thanks ğŸ˜Š")
```

> [!NOTE]
> å› ä¸º UTF-8 æ˜¯é»˜è®¤ç¼–ç ï¼Œæ‰€ä»¥å‰é¢çš„ `u` å¯ä»¥çœç•¥ï¼Œè¿™é‡Œä¸ºäº†æ¸…æ™°è€ŒåŠ ä¸Šï¼Œä¸‹åŒã€‚

```txt
<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \xf0\x9f\x98\x8a'>
```

`tf.string` å¼ é‡å°† byte å­—ç¬¦ä¸²è§†ä¸ºåŸå­å•å…ƒï¼Œå› æ­¤å¯ä»¥å­˜å‚¨ä¸åŒé•¿åº¦çš„ byte å­—ç¬¦ä¸²ã€‚å­—ç¬¦ä¸²é•¿åº¦ä¸åŒ…å«åœ¨å¼ é‡ shape ä¸­ã€‚

```python
tf.constant([u"You're", u"welcome!"]).shape
```

```txt
TensorShape([2])
```

å¦‚æœä½¿ç”¨ Python æ„é€ å­—ç¬¦ä¸²ï¼Œå­—ç¬¦ä¸²å­—é¢é‡é»˜è®¤ä¸º Unicode ç¼–ç ã€‚

## 3. è¡¨ç¤º Unicode

åœ¨ TensorFlow ä¸­æœ‰ä¸¤ç§è¡¨ç¤º Unicode å­—ç¬¦ä¸²çš„æ ‡å‡†æ–¹æ³•ï¼š

- `string` æ ‡é‡ï¼Œä»£ç ç‚¹åºåˆ—ä½¿ç”¨å·²çŸ¥[å­—ç¬¦ç¼–ç ](https://en.wikipedia.org/wiki/Character_encoding)è¿›è¡Œç¼–ç ã€‚
- `int32` å‘é‡ï¼Œæ¯ä¸ªä½ç½®åŒ…å«ä¸€ä¸ªä»£ç ç‚¹ã€‚

ä¾‹å¦‚ï¼Œä¸‹é¢ä¸‰ä¸ªå€¼éƒ½è¡¨ç¤º Unicode å­—ç¬¦ä¸² `"è¯­è¨€å¤„ç†"`ã€‚

1. UTF-8 ç¼–ç çš„ string æ ‡é‡

```python
# Unicode string, UTF-8 ç¼–ç çš„ string æ ‡é‡
text_utf8 = tf.constant(u"è¯­è¨€å¤„ç†")
text_utf8
```

```txt
<tf.Tensor: shape=(), dtype=string, numpy=b'\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86'>
```

2. UTF-16-BE ç¼–ç çš„ string æ ‡é‡

```python
# Unicode string, UTF-16-BE ç¼–ç çš„ string æ ‡é‡
text_utf16be = tf.constant(u"è¯­è¨€å¤„ç†".encode("UTF-16-BE"))
text_utf16be
```

```txt
<tf.Tensor: shape=(), dtype=string, numpy=b'\x8b\xed\x8a\x00Y\x04t\x06'>
```

3. Unicode ä»£ç ç‚¹å‘é‡è¡¨ç¤ºçš„ Unicode å­—ç¬¦ä¸²

```python
# Unicode string, è¡¨ç¤ºä¸º Unicode ä»£ç ç‚¹å‘é‡
text_chars = tf.constant([ord(char) for char in u"è¯­è¨€å¤„ç†"])
text_chars
```

```txt
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>
```

### 3.1 ä¸åŒè¡¨ç¤ºä¹‹é—´çš„è½¬æ¢

TF æä¾›äº†è¿™äº›ä¸åŒè¡¨ç¤ºä¹‹é—´çš„è½¬æ¢åŠŸèƒ½ï¼š

- `tf.strings.unicode_decode`ï¼šå°†ç¼–ç  string æ ‡é‡è½¬æ¢ä¸ºä»£ç ç‚¹å‘é‡
- `tf.strings.unicode_encode`ï¼šå°†ä»£ç ç‚¹å‘é‡è½¬æ¢ä¸ºç¼–ç  string æ ‡é‡
- `tf.strings.unicode_transcode`ï¼šå°†ç¼–ç  string æ ‡é‡è½¬æ¢ä¸ºä¸åŒç¼–ç 

1. string æ ‡é‡è½¬æ¢ä¸ºä»£ç ç‚¹å‘é‡

```python
tf.strings.unicode_decode(text_utf8, input_encoding="UTF-8")
```

```txt
<tf.Tensor: shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>
```

2. ä»£ç ç‚¹å‘é‡è½¬æ¢ä¸º string æ ‡é‡

```python
tf.strings.unicode_encode(text_chars, output_encoding="UTF-8")
```

```txt
<tf.Tensor: shape=(), dtype=string, numpy=b'\xe8\xaf\xad\xe8\xa8\x80\xe5\xa4\x84\xe7\x90\x86'>
```

3. utf-8 ç¼–ç è½¬æ¢ä¸º utf-16-be ç¼–ç 

```python
tf.strings.unicode_transcode(
    text_utf8, input_encoding="UTF8", output_encoding="UTF-16-BE"
)
```

```txt
<tf.Tensor: shape=(), dtype=string, numpy=b'\x8b\xed\x8a\x00Y\x04t\x06'>
```

### 3.2 batch ç»´åº¦

å½“è§£ç å¤šä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œç”±äºä¸åŒå­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦æ•°å¯èƒ½ä¸åŒï¼Œå› æ­¤è¿”å› `tf.RaggedTensor` ç±»å‹ã€‚æœ€é‡Œé¢ç»´åº¦çš„é•¿åº¦å–å†³äºæœ€é•¿å­—ç¬¦ä¸²åŒ…å«çš„å­—ç¬¦æ•°ã€‚

```python
# ä¸€æ‰¹ utf-8 ç¼–ç çš„ Unicode å­—ç¬¦ä¸²
batch_utf8 = [
    s.encode("UTF-8")
    for s in [u"hÃƒllo", u"What is the weather tomorrow", u"GÃ¶Ã¶dnight", u"ğŸ˜Š"]
]
# è½¬æ¢ä¸º unicode ä»£ç ç‚¹
batch_chars_ragged = tf.strings.unicode_decode(batch_utf8, input_encoding="UTF-8")
for sentence_chars in batch_chars_ragged.to_list():
    print(sentence_chars)
```

```txt
[104, 195, 108, 108, 111]
[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]
[71, 246, 246, 100, 110, 105, 103, 104, 116]
[128522]
```

è¿”å›çš„ `tf.RaggedTensor` å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ `tf.RaggedTensor.to_tensor` é€šè¿‡å¡«å……è½¬æ¢ä¸º `tf.Tensor`ï¼ˆå¯†é›†å¼ é‡ï¼‰ï¼Œæˆ–è€…ä½¿ç”¨ `tf.RaggedTensor.to_sparse` è½¬æ¢ä¸º `tf.sparsee.SparseTensor`ï¼ˆç¨€ç–å¼ é‡ï¼‰ã€‚

```python
# è½¬æ¢ä¸ºå¯†é›†å¼ é‡
batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)
print(batch_chars_padded.numpy())
```

```txt
[[   104    195    108    108    111     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]
 [    87    104     97    116     32    105    115     32    116    104
     101     32    119    101     97    116    104    101    114     32
     116    111    109    111    114    114    111    119]
 [    71    246    246    100    110    105    103    104    116     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]
 [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1
      -1     -1     -1     -1     -1     -1     -1     -1]]
```

```python
# è½¬æ¢ä¸ºç¨€ç–å¼ é‡
batch_chars_sparse = batch_chars_ragged.to_sparse()

nrows, ncols = batch_chars_sparse.dense_shape.numpy()
elements = [["_" for i in range(ncols)] for j in range(nrows)]
for (row, col), value in zip(
    batch_chars_sparse.indices.numpy(), batch_chars_sparse.values.numpy()
):
    elements[row][col] = str(value)
# max_width = max(len(value) for row in elements for value in row)
value_lengths = []
for row in elements:
    for value in row:
        value_lengths.append(len(value))
max_width = max(value_lengths)
print(
    "[%s]" % "\n ".join(
        "[%s]" % ", ".join(value.rjust(max_width) for value in row) for row in elements
    )
)
```

```txt
[[   104,    195,    108,    108,    111,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]
 [    87,    104,     97,    116,     32,    105,    115,     32,    116,    104,    101,     32,    119,    101,     97,    116,    104,    101,    114,     32,    116,    111,    109,    111,    114,    114,    111,    119]
 [    71,    246,    246,    100,    110,    105,    103,    104,    116,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]
 [128522,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _,      _]]
```

- ç¼–ç å¤šä¸ªé•¿åº¦ç›¸åŒçš„å­—ç¬¦ä¸²æ—¶ï¼Œä½¿ç”¨ `tf.Tensor` ä½œä¸ºè¾“å…¥

```python
tf.strings.unicode_encode(
    [[99, 97, 116], [100, 111, 103], [99, 111, 119]], output_encoding="UTF-8"
)
```

```txt
<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>
```

- ç¼–ç å¤šä¸ªé•¿åº¦ä¸åŒçš„å­—ç¬¦ä¸²æ—¶ï¼Œä½¿ç”¨ `tf.RaggedTensor` ä½œä¸ºè¾“å…¥

```python
tf.strings.unicode_encode(batch_chars_ragged, output_encoding="UTF-8")
```

```txt
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>
```

å¯¹åŒ…å«å¤šä¸ªå¡«å……æˆ–ç¨€ç–æ ¼å¼å­—ç¬¦ä¸²çš„å¼ é‡ï¼Œåœ¨è°ƒç”¨ `tf.strings.unicode_encode` å‰é¦–å…ˆè½¬æ¢ä¸º `tf.RaggedTensor`

- ç¨€ç–å¼ é‡ï¼Œå…ˆè½¬æ¢ä¸º `tf.RaggedTensor`

```python
tf.strings.unicode_encode(
    tf.RaggedTensor.from_sparse(batch_chars_sparse), output_encoding="UTF-8"
)
```

```txt
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>
```

- å¡«å……å¼ é‡ï¼Œå…ˆè½¬æ¢ä¸º `tf.RaggedTensor`

```python
tf.strings.unicode_encode(
    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1), output_encoding="UTF-8"
)
```

```txt
<tf.Tensor: shape=(4,), dtype=string, numpy=
array([b'h\xc3\x83llo', b'What is the weather tomorrow',
       b'G\xc3\xb6\xc3\xb6dnight', b'\xf0\x9f\x98\x8a'], dtype=object)>
```

## 4. Unicode æ“ä½œ

### 4.1 å­—ç¬¦é•¿åº¦

é€šè¿‡ `tf.strings.length` å‡½æ•°çš„ `unit` å‚æ•°æŒ‡å®šå¦‚ä½•è®¡ç®—å­—ç¬¦é•¿åº¦ã€‚`unit` é»˜è®¤ä¸º `"BYTE"`ï¼Œå…¶å®ƒé€‰é¡¹åŒ…æ‹¬ `"UTF8_CHAR"` æˆ– `"UTF16_CHAR"`ï¼Œç”¨äºæŒ‡å®šç¼–ç å­—ç¬¦ä¸²ä¸­ Unicode codepoints æ•°ã€‚

```python
# åœ¨ UTF8 ä¸­æœ€åä¸€ä¸ªå­—ç¬¦å  4 ä¸ªå­—èŠ‚
thanks = u"Thanks ğŸ˜Š".encode("UTF-8")
num_bytes = tf.strings.length(thanks).numpy()
num_chars = tf.strings.length(thanks, unit="UTF8_CHAR").numpy()
print("{} bytes; {} UTF-8 characters".format(num_bytes, num_chars))
```

```txt
11 bytes; 8 UTF-8 characters
```

### 4.2 å­å­—ç¬¦ä¸²

`tf.strings.substr` å‡½æ•°é€šè¿‡ `unit` å‚æ•°ç¡®å®š `pos`  å’Œ `len` å‚æ•°çš„ offsetsã€‚

```python
# è¿™é‡Œ unit='BYTE' (default). è¿”å›é•¿åº¦ä¸º 1 çš„å•ä¸ªå­—èŠ‚
tf.strings.substr(thanks, pos=7, len=1).numpy()
```

```txt
b'\xf0'
```

```python
# è®¾ç½® unit='UTF8_CHAR', è¿”å› 1 ä¸ª 4 å­—èŠ‚å­—ç¬¦
print(tf.strings.substr(thanks, pos=7, len=1, unit="UTF8_CHAR").numpy())
```

```txt
b'\xf0\x9f\x98\x8a'
```

### 4.3 æ‹†åˆ† Unicode å­—ç¬¦ä¸²

`tf.stringgs.unicode_split` å‡½æ•°å°† unicode å­—ç¬¦ä¸²æ‹†åˆ†ä¸ºå­å­—ç¬¦ä¸²æˆ–å­—ç¬¦ã€‚

```python
tf.strings.unicode_split(thanks, "UTF-8").numpy()
```

```txt
array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\xf0\x9f\x98\x8a'],
      dtype=object)
```

### 4.4 Byte offsets for characters

ä¸ºäº†å¯¹é½ `tf.strings.unicode_decode` ç”Ÿæˆçš„å­—ç¬¦å¼ é‡å’ŒåŸå§‹å­—ç¬¦ä¸²ï¼ŒçŸ¥é“æ¯ä¸ªå­—ç¬¦å¼€å§‹ä½ç½®çš„ offset éå¸¸æœ‰ç”¨ã€‚`tf.strings.unicode_decode_with_offsets` åŠŸèƒ½ä¸ `unicode_decode` ç±»ä¼¼ï¼Œåªæ˜¯é¢å¤–è¿”å›ä¸€ä¸ªåŒ…å«æ¯ä¸ªå­—ç¬¦èµ·å§‹ä½ç½® offset çš„å¼ é‡ã€‚

```python
codepoints, offsets = tf.strings.unicode_decode_with_offsets(u"ğŸˆğŸ‰ğŸŠ", "UTF-8")

for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):
    print("At byte offset {}: codepoint {}".format(offset, codepoint))
```

```txt
At byte offset 0: codepoint 127880
At byte offset 4: codepoint 127881
At byte offset 8: codepoint 127882
```

## 5. Unicode scripts

æ¯ä¸ª Unicode codepoint å±äºä¸€ä¸ªç§°ä¸º [script](https://en.wikipedia.org/wiki/Script_%28Unicode%29) codepoint é›†åˆã€‚å­—ç¬¦çš„ script æœ‰åŠ©äºç¡®å®šå­—ç¬¦æ‰€å±çš„è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œå·²çŸ¥ 'Ğ‘' åœ¨ Cyrillic script ä¸­ï¼Œè¡¨ç¤ºåŒ…å«è¯¥å­—ç¬¦çš„æ–‡æœ¬å¯èƒ½æ¥è‡ª Slavic è¯­è¨€ï¼Œå¦‚ä¿„ç½—æ–¯æˆ–ä¹Œå…‹å…°è¯­ã€‚

TF æä¾› `tf.strings.unicode_script` å‡½æ•°ç”¨äºç¡®å®šæŒ‡å®š codepoint ä½¿ç”¨çš„ scriptã€‚script ä»£ç æ˜¯ `int32` å€¼ï¼Œä¸ [International Components for Unicode, ICU](http://site.icu-project.org/home) çš„ [UScriptCode](icu-project.org/apiref/icu4c/uscript_8h.html) å€¼å¯¹åº”ã€‚

```python
uscript = tf.strings.unicode_script([33464, 1041])  # ['èŠ¸', 'Ğ‘']

print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]
```

```txt
[17  8]
```

`tf.strings.unicode_script` å‡½æ•°ä¹Ÿå¯ä»¥ç”¨äºåŒ…å« codepoints çš„å¤šç»´ `tf.Tensor` æˆ– `tf.RaggedTensor`ï¼š

```python
print(tf.strings.unicode_script(batch_chars_ragged))
```

```txt
<tf.RaggedTensor [[25, 25, 25, 25, 25],
 [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25,
  0, 25, 25, 25, 25, 25, 25, 25, 25]                                      ,
 [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>
```

## 6. ç¤ºä¾‹ï¼šç®€å•åˆ†è¯

åˆ†è¯ï¼ˆsegmentationï¼‰æ˜¯å°†æ–‡æœ¬åˆ†å‰²æˆç±»ä¼¼å•è¯å•å…ƒçš„ä»»åŠ¡ã€‚å¯¹ä½¿ç”¨ç©ºæ ¼åˆ†å‰²å•è¯çš„æ–‡æœ¬ï¼Œè¿™å¾ˆå®¹æ˜“ï¼Œä½†æœ‰äº›è¯­è¨€ï¼ˆå¦‚æ±‰è¯­ã€æ—¥è¯­ï¼‰ä¸ä½¿ç”¨ç©ºæ ¼ï¼Œæœ‰äº›è¯­è¨€ï¼ˆå¦‚å¾·è¯­ï¼‰åŒ…å«é•¿çš„å¤åˆè¯ï¼Œå¿…é¡»æ‹†åˆ†æ‰èƒ½ç†è§£å…¶å«ä¹‰ã€‚åœ¨ web æ–‡æœ¬ä¸­ï¼Œä¸åŒè¯­è¨€å’Œ script ç»å¸¸æ··åœ¨ä¸€èµ·ï¼Œå¦‚ "NYæ ªä¾¡" ï¼ˆçº½çº¦è¯åˆ¸äº¤æ˜“æ‰€ï¼‰ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ script çš„å˜åŒ–æ¥è¿‘ä¼¼å•è¯è¾¹ç•Œï¼Œä»è€Œå®ç°éå¸¸ç²—ç³™çš„åˆ†è¯ï¼ˆæ— éœ€å®ç°ä»»ä½• ML æ¨¡å‹ï¼‰ã€‚è¿™é€‚ç”¨äºä¸Šé¢ "NYæ ªä¾¡" ä¹‹ç±»çš„å­—ç¬¦ä¸²ï¼Œä¹Ÿé€‚ç”¨äºä½¿ç”¨ç©ºæ ¼åˆ†è¯çš„å¤§å¤šæ•°è¯­è¨€ï¼Œå› ä¸ºå„ç§ script å‡å°†ç©ºæ ¼å­—ç¬¦ä½œä¸º USCRIPT_COMMONï¼Œä¸€ç§ä¸åŒäºå®é™…æ–‡æœ¬çš„ä»£ç ã€‚

```python
# dtype: string; shape: [num_sentences]
#
# è¦å¤„ç†çš„å¥å­ã€‚å¯ä»¥ç¼–è¾‘æ­¤è¡Œå°è¯•ä¸åŒè¾“å…¥
sentence_texts = [u"Hello, world.", u"ä¸–ç•Œã“ã‚“ã«ã¡ã¯"]
```

é¦–å…ˆï¼Œå°†å¥å­è§£ç ä¸ºå­—ç¬¦ä»£ç ç‚¹ï¼Œå¹¶æ‰¾åˆ°æ¯ä¸ªå­—ç¬¦çš„ scriptï¼š

```python
# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_codepoint[i, j] is the codepoint for the j'th character in
# the i'th sentence.
sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, "UTF-8")
print(sentence_char_codepoint)

# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_scripts[i, j] is the Unicode script of the j'th character in
# the i'th sentence.
sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)
print(sentence_char_script)
```

```txt
<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46],
 [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>
<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0],
 [17, 17, 20, 20, 20, 20, 20]]>
```

ä½¿ç”¨ script æ ‡è¯†ç¬¦ç¡®å®šå•è¯è¾¹ç•Œã€‚åœ¨æ¯ä¸ªå¥å­çš„å¼€å¤´å’Œ script å’Œå‰é¢å­—ç¬¦ä¸åŒçš„å­—ç¬¦å‰é¢æ·»åŠ å•è¯è¾¹ç•Œã€‚

```python
# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]
#
# sentence_char_starts_word[i, j] is True if the j'th character in the i'th
# sentence is the start of a word.
sentence_char_starts_word = tf.concat(
    [
        tf.fill([sentence_char_script.nrows(), 1], True),
        tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1]),
    ],
    axis=1,
)

# dtype: int64; shape: [num_words]
#
# word_starts[i] is the index of the character that starts the i'th word (in
# the flattened list of characters from all sentences).
word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)
print(word_starts)
```

```txt
tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)
```

å¯ä»¥ä½¿ç”¨è¿™äº› start offsets æ¥æ„å»ºåŒ…å«æ‰€æœ‰ batches çš„å•è¯åˆ—è¡¨çš„ `RaggedTensor`ã€‚

```python
# dtype: int32; shape: [num_words, (num_chars_per_word)]
#
# word_char_codepoint[i, j] is the codepoint for the j'th character in the
# i'th word.
word_char_codepoint = tf.RaggedTensor.from_row_starts(
    values=sentence_char_codepoint.values, row_starts=word_starts
)
print(word_char_codepoint)
```

```txt
<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46],
 [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>
```

æœ€åï¼Œå°† `RaggedTensor` åŒ…å«çš„å•è¯ä»£ç ç‚¹è½¬æ¢ä¸ºå¥å­ï¼Œå¹¶ç¼–ç æˆ UTF-8 å­—ç¬¦å·²ä¾¿äºé˜…è¯»ï¼š

```python
# dtype: int64; shape: [num_sentences]
#
# sentence_num_words[i] is the number of words in the i'th sentence.
sentence_num_words = tf.reduce_sum(tf.cast(sentence_char_starts_word, tf.int64), axis=1)

# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]
#
# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character
# in the j'th word in the i'th sentence.
sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(
    values=word_char_codepoint, row_lengths=sentence_num_words
)
print(sentence_word_char_codepoint)

tf.strings.unicode_encode(sentence_word_char_codepoint, "UTF-8").to_list()
```

```txt
<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]],
 [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>
[[b'Hello', b', ', b'world', b'.'],
 [b'\xe4\xb8\x96\xe7\x95\x8c',
  b'\xe3\x81\x93\xe3\x82\x93\xe3\x81\xab\xe3\x81\xa1\xe3\x81\xaf']]
```

## 7. å‚è€ƒ

- https://www.tensorflow.org/text/guide/unicode
