# 概述

2025-07-03⭐
@author Jiawei Mao
****

## 简介

在数据中发现模式是一个基础问题，有着悠久且成功的历史。例如，Tycho Brahe 在 16 世纪积累的天文观测数据使得 Johannes Kepler 发现行星运动的经验规律，这反过来又为经典力学的发展奠定基础。同样，20 世纪初发现原子光谱的规律性对量子物理的发展和验证起着关键作用。

**模式识别**：使用计算机算法自动发现数据中的规律，并在数据分类等任务中使用这些规律。

**示例：** 手写数字识别
输入：如 **图 1.1** 所示，每个 28x28 像素的图像对应一个数字，因此图像可以表示为长度 784 的向量 $x$。
目的：构建一个模型，输入向量 $x$，输出对应数字 $0,...,9$。

由于不同人的笔记不一样，这个问题并不简单。我们可以尝试手动编写规则或使用启发式方法来根据笔画的形状区分数字，但在实践中，这种方法会导致规则过多或例外的情况过多，性能很差。

<img src="images/2023-12-18-14-23-41.png" width="250">

> **图 1.1** 手写数字示例。

采用机器学习可以获得更好的结果。

- 训练集

将包含 $N$ 个样本的集合 $\{x_1,...,x_N\}$ 称为**训练集**（train set），用来调整自适应模型的参数。
训练集中，图像对应的数字是已知的，用目标向量 $t$ 来表示数字类别。因此，训练集中每个数字图像 $x$，对应一个目标向量 $t$。

机器学习算法可以表示为一个函数 $y(x)$，它以数字图像 $x$ 为输入，生成输出向量 $y$，$y$ 的编码方式与目标向量 $t$ 相同。函数 $y(x)$ 的精确形式在训练阶段根据训练数据确定。

- 测试集

训练好模型，就能用它识别新的数字图像，新的测试图像称为**测试集**（test set）。

正确分类**不同于训练集**的新样本的能力称为**泛化**（generalization）。在实际应用中，训练数据一般只包含所有可能输入向量的一小部分，因此**泛化是模式识别的核心目标**。

## 特征提取

在大多数实际应用中，通常会对原始输入变量进行预处理，将其转换到新的变量空间，使得模式识别问题更容易解决。例如，在数字识别问题中，通常会对数字图像进行平移和缩放，使得每个数字包含在固定大小的框中。这大大降低了每个数字类别的变异性，因为所有数字的位置和比例都相同了，这使得后续模式识别算法更容易区分不同的类别。这个预处理阶段也称为**特征提取**（feature extraction）。需要注意的是，新的测试数据必须使用与训练数据相同的预处理步骤。

**预处理还可以加快计算速度**。例如，在高分辨视频流中实时检测人脸，计算机每秒要处理大量像素，而将这些像素直接呈现给复杂的模式识别算法会带来很大的计算开销。如果只保留足够区分人脸和非人脸的有用特征，将这些特征用作模式识别算法的输入，能显著提高计算速度。例如，可以快速计算矩形区域上图像强度均值，使用一组这样的矩形足以快速检测人脸（Viola and Jones, 2004）。由于这些特征的数量小于像素数量，因此这种预处理也是一种降维操作。在预处理过程中必须小心，避免丢失重要信息，如果这些信息对解决问题很重要，那么系统的整体准确性会受影响。

## 模式识别分类

训练数据包含输入向量及其对应的目标向量的算法称为**监督学习**（supervised learning）：

- 如数字识别问题，其目的是将输入向量映射到有限的离散类别，又称为**分类**（classification）。

- 如果输出包含一个或多个连续变量，则该任务称为**回归**（regression）。如根据反应物浓度、温度和压力预测化学反应的产量就是回归问题。

在其它模式识别问题中，训练数据只有输入向量，没有对应的目标值，这类问题称为**无监督学习**（unsupervised learning），无监督学习的目标可能是：

- 在数据中发现相似样本的无监督学习，称为**聚类**（clustering）
- 确定输入空间中数据的分布，称为**密度估计**（density estimation）
- 将数据从高维空间投影到二维或三维空间，用于可视化

最后，**强化学习**（reinforcement learning, Sutton and Barto, 1998）是在给定条件下寻找合适动作以最大化奖励的问题。与监督学习不同，强化学习没有给出最佳输出的例子，而是要通过试错来发现。通常，学习算法通过一系列状态和动作与环境交互。在许多情况下，当前动作不仅影响即时奖励，还会影响所有后续步骤的奖励。例如，通过适当的强化学习技术，神经网络可以达到高水平的西洋双陆棋（Tesauro, 1994）。对该问题，神经网络必须学习将棋盘位置和骰子结果为输入，产生的移动为输出。实现该目标是方法是让神经网络与自己的副本进行大于 100 万场比赛。该问题的一个主要挑战是，一场西洋双陆棋可能包含上十步棋子，但只有在游戏结束才能获得胜利形式的奖励。因此，必须将奖励归因到导致胜利的所有动作，即使有些动作很好，有些不好。这是一个信用分配问题。强化学习一个重要特征是探索和利用之间的权衡：

- 探索（exploration）：系统尝试新的动作，看看新动作的效果
- 利用（exploitation）：系统利用已知会产生高回报的动作

过分注重探索或利用都会导致结果不好。强化学习仍然是机器学习研究的一个活跃领域。

尽管上面这些任务都需要各自的工具和技术，但它们的许多关键思想是通用的。本章的一个主要目标是以一种相对通俗易懂的方式介绍机器学习的一些重要概念，并用简单的例子来辅助说明。在本书后面，我们将再次看到这些思想用于实际问题的更复杂的模型中。本章后面还介绍三个重要工具，即概率论、决策理论和信息论。虽然这些概念听起来更复杂，但其实不复杂，要想在实际应用中最大限度利用机器学习技术，清晰理解这些概念至关重要。
