# 绪论

2024-07-16 ⭐
@author Jiawei Mao
***

## 课程定位

科学：**是什么**和**为什么**
技术：**怎么做**
工程：做得多快好省
应用：

这门课：科学+技术，少量工程
## 机器学习定义

**经典定义**：利用经验改善系统自身的性能 [T. Mitchell 教科书，1997]

随着该领域的发展，目前主要研究**智能数据分析**的理论和方法，并已成为智能数据分析技术的源泉之一。

大数据->价值

## 机器学习案例

**医学文献筛选**

在”循证医学“（evidence-based medicine）中，针对特定的临床问题，先要对相关研究报告进行详尽评估。

1. 查询 PubMed 以获取候选摘要
2. 人工找出值得全文审读的文章

每项新的研究都要重复这个麻烦的过程！

需要筛选的文章数在不断显著增长！

为了降低成本，Tufts 医学中心引入机器学习技术：

- 邀请专家阅读少量摘要，标记为“有关”或“无关”
- 建分类模型：对文献是否“有关”进行预测

专家只需阅读 50 篇摘要，系统的自动筛选精度就达到 93%。

专家阅读 1000 篇摘要，系统的自动筛选灵敏度达到 95%。

人类专家以前需要阅读 33,000 篇摘要才能获得此效果。

**画作鉴别**

画作鉴别（painting authentication）：确定作品的真伪

该工作对专家知识要求极高：

- 具有较高的绘画艺术修养
- 掌握画家的特定绘画习惯

只有少数专家话费很大精力才能完成分析工作！

很难同时掌握不同时期、不同流派多位画家的绘画风格！

引入机器学习技术：

- 真迹+赝品
- 分类模型
- 自动鉴定画作

对用户要求低、准确度高、适用范围广。

## 典型的机器学习过程

 西瓜数据集：

| 编号  | 色泽  | 根蒂  | 敲声  | 好瓜  |
| --- | --- | --- | --- | --- |
| 1   | 青绿  | 蜷缩  | 浊响  | 是   |
| 2   | 乌黑  | 蜷缩  | 浊响  | 是   |
| 3   | 青绿  | 硬挺  | 清脆  | 否   |
| 4   | 乌黑  | 稍蜷  | 沉闷  | 否   |

标签（label）：类别标记

<img src="images/Pasted image 20240716111923.png" style="zoom: 50%;" />

适用于全局的，称为**模型**；适用于局部的，称为模式(Pattern)。不过大多地方不予区分，统一称为模型。

## 机器学习理论

Leslie Valiant 的计算学习理论，其中最重要的理论模型为 PAC（Probably Approximately Correct），即概率近似正确模型，表达式为：

$$
P(|f(x)-y|\le \epsilon) \ge 1-\delta
$$
函数 $f$ 就是我们想要的模型，$y$ 是真实值。

当专业知识不能给出准确结果，就需要用机器学习从数据学习模式。

问题：

- P 问题，在多项式时间内可解决的问题
- NP 问题，非多项式时间内可解决的问题，但很容易验证答案对不对

**P 类问题**是可以在多项式时间内**解决并验证**的一类问题，**NP 类问题**是可以多项式时间但是不确定能否在多项式时间内解决的一类问题。

P 类问题是一种特殊的 NP 问题。P=NP，指是否可以在多项式时间内解决 NP 问题，将其转换为 P 类问题。

超出 NP 问题，无法检验答案是否最佳的问题。

因为机器学习研究的问题很多无法验证是否最佳，即是超出 NP 的问题，所以 $\epsilon$ 无法为 0。

> [!NOTE]
>
> 机器学习，以很高概率得到一个很好的模型，即概率近似正确。

## 基本术语

<img src="images/Pasted image 20240716111923.png" style="zoom: 50%;" />

关于数据集的术语：

- **数据集**：所有数据构成的集合
  - 训练：用数据建立模型的过程
  - 测试：在新的数据上测试训练好的模型的性能
    - 新的数据答案已知
    - 新的数据在训练集中没有
- **示例**（instance）：不包含最后的标记（没有结果）
- **样例**（example）：示例+类别标记（有结果）
- **样本**（sample）：定义比较模糊，有时候指样例，有时候指整个数据集，根据上下文理解
- **属性**（attribute），特征（feature）：属性和特征含义相同；
  - 属性值：特定属性的取值
- **属性空间**，样本空间，输入空间：均指所有属性一起定义的空间
  - 特征向量（feature vector）：由属性定义的向量，一个特征向量对应一个示例
- **标记空间**，输出空间



关于模型的术语：

- **模型**，包含总结出来的规律，就是通常所说的**假设**（hypothesis），即学习到的模型，构成一个假设。
  - 学习过程：在所有假设组成的空间中搜索的过程

- 真实的模型，称为**真相**（ground-truth），即正确的答案。

- $f(x)$ 就是学到的假设，$y$ 就是 ground-truth。



关于输出的概念：

- 分类（输出离散），回归（输出离散）
- 二分类，多分类
- 正类，反类：假设可交换，即这两类的分布和许多性质近似，比如比例近似



关于学习任务的术语：

- 监督学习（supervised learning）
- 无监督学习（unsupervised learning）：聚类、密度估计



其它术语：

- 未见样本（unseen instance）
- 未知”分布“
- 独立同分布（i.i.d.）：独立从同一个分布产生，即机器学习假设拿到的所有数据都来自一个潜在的分布
- 泛化（generalization）：从特殊到一般
  - 特化（specialization）：从一般到特殊

> [!TIP]
>
> 突破独立同分布，是机器学习的前沿技术。

## 归纳偏好

机器学习算法在学习过程中对某种类型假设的偏好。

归纳偏好（inductive bias）

<img src="./images/image-20240716133045592.png" alt="image-20240716133045592" style="zoom: 33%;" />

**任何一个有效的机器学习算法必有其偏好**。

一般原则：**奥卡姆剃刀**（Occam's razor），若非必要，勿增实体。

> [!WARNING]
>
> 科研也是一样，当能用简单的方法解决问题，不要试图将其复杂化，也不要提前优化。

所以上图采用 A 模型，它更简单，更平滑。

**学习算法的归纳偏好是否与问题本身匹配**，大多数时候直接决定了算法能够取得好的性能！

> [!TIP]
>
> 学习、搜索和优化，本质上是相同的概念。
>
> 算法没有好坏，更重要的是算法的假设与问题匹配。

## NFL 定理

<img src="./images/image-20240716134455835.png" alt="image-20240716134455835" style="zoom: 50%;" />

NFL 定理（**no free lunch**）：一个算法 $L_a$ 若在某些问题上比另一个算法 $L_b$ 好，必存在另一个问题 $L_b$ 比 $L_a$ 好。

**NFL 定理的重要前提**：所有问题出现的机会相同，或所有问题同等重要。

实际情形并非如此，我们通常只关注自己正在试图解决的问题。

**脱离具体问题**，空谈“什么学习算法更好”毫无意义。

> 具体问题，具体分析！

机器学习并非“十大套路”的简单堆积，现实任务千变万化，以有限的套路应对无限的问题，焉有不败？

最优方案：**按需设计**。

